---
layout: post
title: The racism hidden in your camera
image: 
---

Racism is a human trait, but cameras are presumably impartial. They capture reality as it is, not as we believe it to be. But what if our cameras had been unintentionally programmed with algorithms that treat white people differently than black people?

Can a machine be racist? Anyone reading this can conduct a simple experiment to find out the truth or falsehood of this question. Simply take your camera or camera phone, and take two pictures, one of a white person, and one of a person with dark skin. You will likely find that the second person is poorly rendered in the photo compared to the first.

I opened the newspaper recently—my parents still get a paper copy—and looked at the striking difference between two photographs—one of a white man, one dark-skinned. Here they are. See if you can spot the racism inherent in the pictures.

TODO INSERT PHOTOS

The poor quality of the second image (Jagpreet Singh, leader of the federal NDP) is not an accident, it’s a result of the way that cameras and photo display systems work.

A modern camera has been imbued with a certain amount of artificial intelligence that enables it to locate faces as you take a picture, and it then adjusts the brightness, contrast, and colour to make the face clearly visible. The software algorithm that performs these measurements is highly optimized technology that operates in the blink of an eye. It then sacrifices other, less important parts of the picture, in order to make sure that those all important faces are clearly rendered.

If we find that a white's man face is well rendered, and a dark-skinned man's face is dark and indistinct, we might do well to wonder if there is a problem with the software. And indeed, there is a long history, going back to film, of testing photo rendering on white people, and mostly ignoring people with other skin colours. For example, Kodak for years used the "Shirley Card", a photo of a white woman with brown hair to calibrate all of their photo processing. They only adjusted it after complaints from chocolate makers.

In today's digital cameras, face recognition uses artificial intelligence algorithms that are trained on large numbers of images, a set of photos that are meant to be representative of the people we will all be taking pictures of. There's a whole process of collecting, analysing and preparing these "training sets", and if racial bias creeps into the process, you could wind up with a lot of well-prepared photos of white people and very few of darker-skinned people. When the AI is trained, it inherits this bias, and the software, without any intention, itself becomes biased.

This problem gets worse, though, as artificial intelligence and face recognition go beyond correctly exposing photographs, and move into identifying individuals. In various real-world cases, AI algorithms have been found to be more likely to mis-identify Black people, in some cases sending the wrong person to jail. As we move into a more machine-driven society, the stakes of systemic racism in our software rise higher and higher. What if in the future, a self-driven car sees a white person and doesn't see a Black person? Lives are, in a very real way, at stake.

If there's a lesson here, it's that racism is all-pervasive. It's not just about police violence, or a few bad apples. It goes deep, so deep that it's contained in a device that almost everyone reading this article has in their pocket. The next time you take a picture, perhaps take a moment to reflect on what a small thing a camera is to hide so much racism.

References:

* [The Racial Bias Built Into Photography (New York Times)](https://www.nytimes.com/2019/04/25/lens/sarah-lewis-racial-bias-photography.html)
* [Light And Dark: The Racial Biases That Remain In Photography (NPR)](https://www.npr.org/sections/codeswitch/2014/04/16/303721251/light-and-dark-the-racial-biases-that-remain-in-photography)
* [‘12 Years a Slave,’ ‘Mother of George,’ and the aesthetic politics of filming black skin (Washington Post)](https://www.washingtonpost.com/entertainment/movies/12-years-a-slave-mother-of-george-and-the-aesthetic-politics-of-filming-black-skin/2013/10/17/282af868-35cd-11e3-80c6-7e6dd8d22d8f_story.html)
* [10 Tips for Photographing Darker Skin Tones (Adobe)](https://create.adobe.com/2017/11/28/_10_tips_for_photographing_darker_skin_tones.html)
